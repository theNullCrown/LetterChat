{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = self.load_data(file_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "        # Add a new padding token if it doesn't exist\n",
    "        if '[PAD]' not in self.tokenizer.get_vocab():\n",
    "            self.tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        prompt = self.data[idx]['prompt']\n",
    "\n",
    "        encoded_prompt = self.tokenizer.encode_plus(\n",
    "            prompt,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoded_prompt['input_ids'].squeeze(),\n",
    "            'attention_mask': encoded_prompt['attention_mask'].squeeze(),\n",
    "        }\n",
    "\n",
    "    def load_data(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Average Loss: 1.4178\n",
      "Epoch 2/20 - Average Loss: 1.3504\n",
      "Epoch 3/20 - Average Loss: 1.2795\n",
      "Epoch 4/20 - Average Loss: 1.2374\n",
      "Epoch 5/20 - Average Loss: 1.1359\n",
      "Epoch 6/20 - Average Loss: 1.0853\n",
      "Epoch 7/20 - Average Loss: 1.0490\n",
      "Epoch 8/20 - Average Loss: 0.9810\n",
      "Epoch 9/20 - Average Loss: 0.9713\n",
      "Epoch 10/20 - Average Loss: 0.9317\n",
      "Epoch 11/20 - Average Loss: 0.8866\n",
      "Epoch 12/20 - Average Loss: 0.8361\n",
      "Epoch 13/20 - Average Loss: 0.8249\n",
      "Epoch 14/20 - Average Loss: 0.7961\n",
      "Epoch 15/20 - Average Loss: 0.7500\n",
      "Epoch 16/20 - Average Loss: 0.7022\n",
      "Epoch 17/20 - Average Loss: 0.6953\n",
      "Epoch 18/20 - Average Loss: 0.6886\n",
      "Epoch 19/20 - Average Loss: 0.6200\n",
      "Epoch 20/20 - Average Loss: 0.6357\n"
     ]
    }
   ],
   "source": [
    "# Define your dataset and model\n",
    "dataset = PromptDataset('../data/autocomplete.json')\n",
    "model = AutoModelForCausalLM.from_pretrained('../models/autocompletion')\n",
    "\n",
    "# Define your training parameters\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "learning_rate = 2e-5\n",
    "\n",
    "# Create a DataLoader for batching and shuffling the data\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Set device (GPU if available, else CPU)\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Set the optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "model.save_pretrained('../models/autocompletion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: Dear Hiring Manager, I am writing to apply for the software engineer position at your company. With a strong background in software development and a passion for creating innovative solutions, I believe I can contribute to your company's success. In my previous role, I developed and implemented complex software solutions that resulted in significant revenue growth. I am confident in my ability to contribute my skills and expertise to your company's success. Thank you for considering my application. Sincerely, [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name] [Your Name]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('../models/autocompletion')\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "prompt = \"Dear Hiring Manager, I am writing to apply for\"\n",
    "\n",
    "# Tokenize the input text\n",
    "encoded_input = tokenizer.encode_plus(\n",
    "    prompt,\n",
    "    add_special_tokens=True,\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "# Perform inference\n",
    "input_ids = encoded_input['input_ids']\n",
    "outputs = model(input_ids)\n",
    "generated_ids = model.generate(input_ids, max_length=200, num_return_sequences=1, num_beams=5)\n",
    "\n",
    "for generated_id in generated_ids:\n",
    "    completion = tokenizer.decode(generated_id, skip_special_tokens=False)\n",
    "    print(\"Completion:\", completion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
